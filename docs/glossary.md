---
title: Glossary of terms.
description: Glossary of terms. DBConvert Stream.
layout: doc
lastUpdated: true
---
# {{ $frontmatter.title }}

The glossary contains an alphabetical list of terms that you may come across in DBConvert Streamâ€™s documentation. Click on a letter to jump to the relevant section of the alphabet.


## A

### Adapter.
See [Source Reader](#source-reader)

## B

### Binary Log (Binlog) 
Binary Log (Binlog) is a collection of log files generated by MySQL server instance that records information about data modifications and data object modifications. Typically binary logs are used for data replication and data recovery.

## C

### Change Data Capture
Change data capture is a technology that retrieves row-level events from Database Transaction Logs generated by a Database engine. 
Read [What is Change Data Capture](/sources/what-is-cdc)


## D

### DDL statements
DDL refers to Data Definition Language, a subset of SQL statements that change the structure of the database schema in some way, typically by creating, deleting, or modifying schema objects such as databases, tables, and views. 


### Destination.
See [Target](#target)

### Data stream.
See [Event stream](#event-stream)

## E

### Event.
A fundamental unit of data that represents the creation, update, or deletion of information in the Source and can be replicated to a Target system. For example, a new record in a PostgreSQL, or updated item details in the Items table in MySQL.

### Event hub
Event Hub service is used to connect Source Readers with Target Writer. Events coming from a Source accumulated in Event Hub to be consumed by Target.

### Event stream.
An Event stream is composed of a series of events, much as a table in a SQL environment is composed of rows. Each event is a fixed sequence of data elements corresponding to the stream's type.
For example, take a system that continuously creates data. Each data point in that system represents an event. A continuous stream of those data points, or events, is referred to as an event stream.

A stream is a table data in the move. Think of a never-ending table where new data appears as the time goes. A stream is such a table. One record or a row in a stream is called an event.


## I

### Ingestion
The act of retrieving or fetching data from the Source.

## L

### Logical Replication
Logical Replication is applicable for the Postgres Source types. In this mode, data is replicated using Postgres Write Ahead Log (WAL) set at a logical level (starting from Postgres version 10 and above). 

Read [PostgreSQL CDC Reader](/sources/postgresql/) section for steps to set up WAL for logical replication.

## M

### Metrics
A measure for insights such as counters of events coming from sources, transferred to targets, elapsed time.

## R

### Reader
See [Source Reader](#source-reader)

### Replication
The collective process of ingesting data from a Source, and subsequently loading it to the Target or data warehouse.

## S

### Sink
A synonym for Target. See [Target](#target).

### Source
DBConvert Stream readers collects data from external sources such as MySQL, PostgreSQL and writes collected events to a Target system of your choice.

### Source Reader
Source Reader continuously collects data events from a source. Ingested data is passed to [Event Hub](#event-hub) to be consumed by Target Writers.

### Stream
See [Event stream](#event-stream)

## T

### Target
A Target is any database or data warehouse to which you want to replicate your data from a Source.

### Target Writer.
Target writes subscribes to events in Event Hub. Target Writer writes consumed Events (database records) continuously to either target databases.

## W

### Warehouse
A storage of the data accumulated from a wide range of heterogeneous Sources, generally used for data analysis and reporting. For example, Amazon Redshift, Google BigQuery or Snowflake.


### Write Ahead Log (WAL)
See [Logical Replication](#logical-replication)

